{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often than not data published on the web are not available in a structured dataset such as those we used in the other labs. Retrieving data requires going through the web pages, examine the [HTML]() code and extract the information. This technique is also known as [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping). Clearly it can be extremely tedious.\n",
    "\n",
    "We will work with the Python module [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) that provides a nice set of tools for extracting information from web pages. The information that we will extract is located in the [BBC Food Recipes database](https://www.bbc.co.uk/food/recipes). We wish to retrieve the Food Recipes available and store them into a document database where each recipe becomes a separate document. We will use the [MongoDB](https://www.mongodb.com/what-is-mongodb) and the Database-as-a-service provider [mLab](https://mlab.com/).\n",
    "\n",
    "The first important step before diving into the code is to use your browser to inspect the HTML code of the pages that we will scap. All major browsers offer developer tools that present the HTML code in a human readable format. For example [Mozila Firefox Developer Tools](https://developer.mozilla.org/en-US/docs/Tools/Page_Inspector/How_to/Examine_and_edit_HTML). We will work with the following pages:\n",
    "* [Ingredients Index from A to Z](http://www.bbc.co.uk/food/ingredients)\n",
    "* [List of Ingredients](http://www.bbc.co.uk/food/ingredients/by/letter/a)\n",
    "* [List of Recipes for a specific Ingredient](http://www.bbc.co.uk/food/acidulated_water)\n",
    "* [Recipe](https://www.bbc.co.uk/food/recipes/roman-style_saltimbocca_44940)\n",
    "\n",
    "For each recipe we wish to extract and store as a document the following information:\n",
    "* Name\n",
    "* URL to BBC web site\n",
    "* Preparation Time\n",
    "* Cooking Time\n",
    "* Servings\n",
    "* List of Ingredients\n",
    "* Related Recipes\n",
    "\n",
    "## Scaping data\n",
    "\n",
    "We will start with the first page in order to retrieve the list of ingredients for a specific ingredient index letter. We start with the [List of Ingredients for Letter A](http://www.bbc.co.uk/food/ingredients/by/letter/a). \n",
    "\n",
    "If you inspect the HTML code of the page (via your browser) you will identify an [HTML order list tag](https://www.w3schools.com/tags/tag_ol.asp) containing one [HTML list item tag](https://www.w3schools.com/tags/tag_li.asp) for each ingredient. The URL of the page of ingredient is included in an [HTML link tag](https://www.w3schools.com/tags/tag_a.asp). Here is a short extract:\n",
    "\n",
    "```html\n",
    "<ol class=\"resources foods grid-view\">\n",
    "                <li class=\"resource food\" id=\"ackee\">\n",
    "                    <a href=\"/food/ackee\">\n",
    "                        <img src=\"http://ichef.bbci.co.uk/food/ic/food_16x9_111/foods/fruit_and_vegetables_16x9.jpg\" alt=\"ackee\" width=\"111\" height=\"63\">\n",
    "                        Ackee                    </a>\n",
    "                                    </li>\n",
    "  ....                                    \n",
    "                                    </ol>\n",
    "```\n",
    "\n",
    "The above information can be easily extracted from the web site using the [find all](http://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python) method of BeautifulSoup.\n",
    "\n",
    "We first start by retrieving the contents of the page http://www.bbc.co.uk/food/ingredients/by/letter/a using [requests](http://docs.python-requests.org/en/master/#) python library for using the HTTP protocol in a simple and straight-forward way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.bbc.co.uk/food/ingredients/by/letter/a'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pass the contents of the HTTP response to BeautifulSoup so that the contents are parsed and converted into a python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to search the processed HTML page using the *find_all* method. We are looking for those ```<a>``` tags that contain the address of each individual ingredient. This will list all the links contained in the page, which are much more than those that we look for. So we will narrow down the search by looking into those that are of the form\n",
    "```/food/```. We do this by inspecting the *href* attribute of the ```<a>``` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/food/\n",
      "/food/\n",
      "/food/\n",
      "/food/recipes/\n",
      "/food/seasons\n",
      "/food/occasions\n",
      "/food/cuisines\n",
      "/food/dishes\n",
      "/food/chefs\n",
      "/food/programmes\n",
      "/food/ingredients\n",
      "/food/techniques\n",
      "/food/about\n",
      "/food/my/favourites\n",
      "/food/ingredients\n",
      "/food/ingredients/by/letter/b\n",
      "/food/ingredients/by/letter/c\n",
      "/food/ingredients/by/letter/d\n",
      "/food/ingredients/by/letter/e\n",
      "/food/ingredients/by/letter/f\n",
      "/food/ingredients/by/letter/g\n",
      "/food/ingredients/by/letter/h\n",
      "/food/ingredients/by/letter/i\n",
      "/food/ingredients/by/letter/j\n",
      "/food/ingredients/by/letter/k\n",
      "/food/ingredients/by/letter/l\n",
      "/food/ingredients/by/letter/m\n",
      "/food/ingredients/by/letter/n\n",
      "/food/ingredients/by/letter/o\n",
      "/food/ingredients/by/letter/p\n",
      "/food/ingredients/by/letter/q\n",
      "/food/ingredients/by/letter/r\n",
      "/food/ingredients/by/letter/s\n",
      "/food/ingredients/by/letter/t\n",
      "/food/ingredients/by/letter/u\n",
      "/food/ingredients/by/letter/v\n",
      "/food/ingredients/by/letter/w\n",
      "/food/ingredients/by/letter/y\n",
      "/food/ingredients/by/letter/z\n",
      "/food/acidulated_water\n",
      "/food/ackee\n",
      "/food/acorn_squash\n",
      "/food/aduki_beans\n",
      "/food/egg_liqueur\n",
      "/food/agar-agar\n",
      "/food/ale\n",
      "/food/aleppo_pepper\n",
      "/food/alfalfa_sprouts\n",
      "/food/allspice\n",
      "/food/almond\n",
      "/food/almond#related-foods\n",
      "/food/almond_essence\n",
      "/food/almond_extract\n",
      "/food/almond_milk\n",
      "/food/amaranth\n",
      "/food/amaretti\n",
      "/food/anchovy\n",
      "/food/anchovy#related-foods\n",
      "/food/anchovy_essence\n",
      "/food/angelica\n",
      "/food/bitters\n",
      "/food/anise\n",
      "/food/apple\n",
      "/food/apple#related-foods\n",
      "/food/apple_chutney\n",
      "/food/apple_juice\n",
      "/food/apple_sauce\n",
      "/food/apricot\n",
      "/food/apricot#related-foods\n",
      "/food/apricot_jam\n",
      "/food/arborio_rice\n",
      "/food/arborio_rice#related-foods\n",
      "/food/arbroath_smokie\n",
      "/food/argan_oil\n",
      "/food/arrowroot\n",
      "/food/artichoke\n",
      "/food/artichoke#related-foods\n",
      "/food/asafoetida\n",
      "/food/asparagus\n",
      "/food/aubergine\n",
      "/food/aubergine#related-foods\n",
      "/food/avocado\n",
      "/food/avocado#related-foods\n",
      "/food/ingredients\n",
      "/food/ingredients/by/letter/b\n",
      "/food/ingredients/by/letter/c\n",
      "/food/ingredients/by/letter/d\n",
      "/food/ingredients/by/letter/e\n",
      "/food/ingredients/by/letter/f\n",
      "/food/ingredients/by/letter/g\n",
      "/food/ingredients/by/letter/h\n",
      "/food/ingredients/by/letter/i\n",
      "/food/ingredients/by/letter/j\n",
      "/food/ingredients/by/letter/k\n",
      "/food/ingredients/by/letter/l\n",
      "/food/ingredients/by/letter/m\n",
      "/food/ingredients/by/letter/n\n",
      "/food/ingredients/by/letter/o\n",
      "/food/ingredients/by/letter/p\n",
      "/food/ingredients/by/letter/q\n",
      "/food/ingredients/by/letter/r\n",
      "/food/ingredients/by/letter/s\n",
      "/food/ingredients/by/letter/t\n",
      "/food/ingredients/by/letter/u\n",
      "/food/ingredients/by/letter/v\n",
      "/food/ingredients/by/letter/w\n",
      "/food/ingredients/by/letter/y\n",
      "/food/ingredients/by/letter/z\n",
      "/food/\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    if (link.get('href').startswith('/food/')):\n",
    "        print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Judging from the above output it is clear that we need to refine the list further in order to explude the links that are not related to ingredients:\n",
    "* The /food/ links\n",
    "* The links pointing to the Ingredient Index\n",
    "* The links pointing to anchors (#) within an ingredient page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/food/recipes/\n",
      "/food/seasons\n",
      "/food/occasions\n",
      "/food/cuisines\n",
      "/food/dishes\n",
      "/food/chefs\n",
      "/food/programmes\n",
      "/food/techniques\n",
      "/food/about\n",
      "/food/my/favourites\n",
      "/food/acidulated_water\n",
      "/food/ackee\n",
      "/food/acorn_squash\n",
      "/food/aduki_beans\n",
      "/food/egg_liqueur\n",
      "/food/agar-agar\n",
      "/food/ale\n",
      "/food/aleppo_pepper\n",
      "/food/alfalfa_sprouts\n",
      "/food/allspice\n",
      "/food/almond\n",
      "/food/almond_essence\n",
      "/food/almond_extract\n",
      "/food/almond_milk\n",
      "/food/amaranth\n",
      "/food/amaretti\n",
      "/food/anchovy\n",
      "/food/anchovy_essence\n",
      "/food/angelica\n",
      "/food/bitters\n",
      "/food/anise\n",
      "/food/apple\n",
      "/food/apple_chutney\n",
      "/food/apple_juice\n",
      "/food/apple_sauce\n",
      "/food/apricot\n",
      "/food/apricot_jam\n",
      "/food/arborio_rice\n",
      "/food/arbroath_smokie\n",
      "/food/argan_oil\n",
      "/food/arrowroot\n",
      "/food/artichoke\n",
      "/food/asafoetida\n",
      "/food/asparagus\n",
      "/food/aubergine\n",
      "/food/avocado\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    linkURL = link.get('href')\n",
    "    if (linkURL.startswith('/food/')):\n",
    "        if (linkURL == '/food/'):\n",
    "            continue\n",
    "            \n",
    "        if (linkURL.find('#related-foods') > 0):\n",
    "            continue\n",
    "            \n",
    "        if (linkURL.startswith('/food/ingredients') > 0):\n",
    "            continue\n",
    "            \n",
    "        print(linkURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We narrowed down the list, yet there are still some links that are not related to ingredients. These do not seem to follow a patern, so we will have to note them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/food/acidulated_water\n",
      "/food/ackee\n",
      "/food/acorn_squash\n",
      "/food/aduki_beans\n",
      "/food/egg_liqueur\n",
      "/food/agar-agar\n",
      "/food/ale\n",
      "/food/aleppo_pepper\n",
      "/food/alfalfa_sprouts\n",
      "/food/allspice\n",
      "/food/almond\n",
      "/food/almond_essence\n",
      "/food/almond_extract\n",
      "/food/almond_milk\n",
      "/food/amaranth\n",
      "/food/amaretti\n",
      "/food/anchovy\n",
      "/food/anchovy_essence\n",
      "/food/angelica\n",
      "/food/bitters\n",
      "/food/anise\n",
      "/food/apple\n",
      "/food/apple_chutney\n",
      "/food/apple_juice\n",
      "/food/apple_sauce\n",
      "/food/apricot\n",
      "/food/apricot_jam\n",
      "/food/arborio_rice\n",
      "/food/arbroath_smokie\n",
      "/food/argan_oil\n",
      "/food/arrowroot\n",
      "/food/artichoke\n",
      "/food/asafoetida\n",
      "/food/asparagus\n",
      "/food/aubergine\n",
      "/food/avocado\n"
     ]
    }
   ],
   "source": [
    "unrelated = ['/food/recipes/', '/food/seasons', '/food/occasions', '/food/cuisines', '/food/dishes', \n",
    "             '/food/chefs', '/food/programmes', '/food/techniques', '/food/about', '/food/my/favourites']\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    linkURL = link.get('href')\n",
    "    if (linkURL.startswith('/food/')):\n",
    "        if (linkURL == '/food/'):\n",
    "            continue\n",
    "            \n",
    "        if (linkURL.find('#related-foods') > 0):\n",
    "            continue\n",
    "            \n",
    "        if (linkURL.startswith('/food/ingredients')):\n",
    "            continue\n",
    "\n",
    "        if (linkURL in unrelated):\n",
    "            continue\n",
    "            \n",
    "        print(linkURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready, we can convert this piece of code into a function that returns the extracted links in a form of a list. This way we will be able to go through all the letters of the alphabet and one by one collect all the ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractIngredients(soup):\n",
    "    ingredients = []\n",
    "    unrelated = ['/food/recipes/', '/food/seasons', '/food/occasions', '/food/cuisines', '/food/dishes', \n",
    "                 '/food/chefs', '/food/programmes', '/food/techniques', '/food/about', '/food/my/favourites']\n",
    "\n",
    "    for link in soup.find_all('a'):\n",
    "        linkURL = link.get('href')\n",
    "        if (linkURL.startswith('/food/')):\n",
    "            if (linkURL == '/food/'):\n",
    "                continue\n",
    "\n",
    "            if (linkURL.find('#related-foods') > 0):\n",
    "                continue\n",
    "\n",
    "            if (linkURL.startswith('/food/ingredients')):\n",
    "                continue\n",
    "\n",
    "            if (linkURL in unrelated):\n",
    "                continue\n",
    "\n",
    "            ingredients.append(linkURL[6:])\n",
    "    \n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Going through all the alphabet names](https://stackoverflow.com/questions/17182656/how-do-i-iterate-through-the-alphabet-in-python-please) and extracting the ingredients listed on the website is not a simple iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "ingredients = []\n",
    "for letter in ascii_lowercase:\n",
    "    url = 'http://www.bbc.co.uk/food/ingredients/by/letter/'+letter\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    ingredients += extractIngredients(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your Internet connection this might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acidulated_water',\n",
       " 'ackee',\n",
       " 'acorn_squash',\n",
       " 'aduki_beans',\n",
       " 'egg_liqueur',\n",
       " 'agar-agar',\n",
       " 'ale',\n",
       " 'aleppo_pepper',\n",
       " 'alfalfa_sprouts',\n",
       " 'allspice',\n",
       " 'almond',\n",
       " 'almond_essence',\n",
       " 'almond_extract',\n",
       " 'almond_milk',\n",
       " 'amaranth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting List of Recipes\n",
    "\n",
    "Now that we have extracted all the ingredients listed on the BBC food recipes dataset we move one with extracting the recipes by scraping each ingredient. \n",
    "\n",
    "Again, we start by exploring the page with our favorite browser. Once again the information (recipes) that we look for can be found within the ```<a>``` tags and in particular the *href* attribute. However, now, we look for those links that start with */food/recipes/*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.bbc.co.uk/food/acidulated_water'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/food/recipes/barbecue_baby_back_ribs_42228\n",
      "/food/recipes/derry_duck_and_64105\n",
      "/food/recipes/roasted_salt_marsh_lamb_13899\n",
      "/food/recipes/roman-style_saltimbocca_44940\n",
      "/food/recipes/honeyandzaatarglazed_91314\n",
      "/food/recipes/terrineofcapricorngo_81701\n",
      "/food/recipes/search?keywords=acidulated water\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    linkURL = link.get('href')\n",
    "    if (linkURL.startswith('/food/recipes/')):\n",
    "        if (linkURL == '/food/recipes/'):\n",
    "            continue\n",
    "            \n",
    "        print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are done much faster. Notice that a link to the *search* page is also include. Let's make this also a function so that we can extract the recipies for all ingredients in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractRecipes(soup):\n",
    "    recipes = []\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        linkURL = link.get('href')\n",
    "        if (linkURL.startswith('/food/recipes/')):\n",
    "            if (linkURL == '/food/recipes/'):\n",
    "                continue\n",
    "                \n",
    "            if (linkURL.find('/search') > 0):\n",
    "                continue                                        \n",
    "\n",
    "            recipes.append(link.get('href')[14:])\n",
    "    \n",
    "    return recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to go through all the ingredients we extracted previously and one by one also retrieve the recipes. However, as we do this, we can also store the index of ingredients and build the reverse index for recipes.\n",
    "\n",
    "## Building a Reverse Index\n",
    "\n",
    "For the indexes we work with dictionaries. As we go through the list we keep one dictionary using as key the ingredient and a second one for the recipe. For each key we will store a list of all the items connected to it. So for the first dictionary, each ingredients will contain a list of recipes. For the second dictionary, each recipe will be connected to a list of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acidulated_water 6\n",
      "ackee 4\n",
      "acorn_squash 4\n",
      "aduki_beans 1\n",
      "egg_liqueur 1\n",
      "agar-agar 7\n",
      "ale 17\n",
      "aleppo_pepper 1\n",
      "alfalfa_sprouts 4\n",
      "allspice 36\n",
      "almond 38\n",
      "almond_essence 9\n",
      "almond_extract 14\n",
      "almond_milk 1\n",
      "amaranth 13\n",
      "amaretti 11\n",
      "anchovy 22\n",
      "anchovy_essence 6\n",
      "angelica 3\n",
      "bitters 4\n",
      "anise 5\n",
      "apple 45\n",
      "apple_chutney 9\n",
      "apple_juice 28\n",
      "apple_sauce 10\n",
      "apricot 24\n",
      "apricot_jam 15\n",
      "arborio_rice 14\n",
      "arbroath_smokie 7\n",
      "argan_oil 1\n",
      "arrowroot 18\n",
      "artichoke 19\n",
      "asafoetida 11\n",
      "asparagus 24\n",
      "aubergine 23\n",
      "avocado 25\n",
      "bacon 32\n",
      "bagel 12\n",
      "baguette 22\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='www.bbc.co.uk', port=80): Max retries exceeded with url: /food/baked_beans (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fde9583b908>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 137\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                                                   body=body, headers=headers)\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 146\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <requests.packages.urllib3.connection.HTTPConnection object at 0x7fde9583b908>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    375\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    609\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 610\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    611\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='www.bbc.co.uk', port=80): Max retries exceeded with url: /food/baked_beans (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fde9583b908>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f0c18fc9352d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mingredients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.bbc.co.uk/food/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mthislist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractRecipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    466\u001b[0m         }\n\u001b[1;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='www.bbc.co.uk', port=80): Max retries exceeded with url: /food/baked_beans (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fde9583b908>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))"
     ]
    }
   ],
   "source": [
    "indexIngredients = {}\n",
    "indexRecipes = {}\n",
    "\n",
    "recipes = []\n",
    "for item in ingredients:\n",
    "    url = 'http://www.bbc.co.uk/food/' + item\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    thislist = extractRecipes(soup)\n",
    "    \n",
    "    # produce short debug to keep track of progress\n",
    "    print(item, len(thislist))\n",
    "    \n",
    "    recipes += thislist\n",
    "    \n",
    "    # Update Ingredients index\n",
    "    indexIngredients[item] = thislist\n",
    "    \n",
    "    # update Recipes index    \n",
    "    for recipe in thislist:\n",
    "        recipeIngredients = indexRecipes.get(recipe, [])        \n",
    "        recipeIngredients.append(item)\n",
    "        indexRecipes[recipe] = recipeIngredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, this will take a while. However this time, because it is a quite long list of ingredients, it is reasonable to get an error that interrupts the process and we have to restart. We need to implement an error handling mechanism using [python error & exceptions](https://docs.python.org/3/tutorial/errors.html) mechanism.\n",
    "\n",
    "We will use a very basic repeat mechanism that will examine one by one the items and every time an error is encountered we will repeat the search until eventually the page is properly scappred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acidulated_water 6\n",
      "ackee 4\n",
      "acorn_squash 4\n",
      "aduki_beans 1\n",
      "egg_liqueur 1\n",
      "agar-agar 7\n",
      "ale 17\n",
      "aleppo_pepper 1\n",
      "alfalfa_sprouts 4\n",
      "allspice 36\n",
      "almond 38\n",
      "almond_essence 9\n",
      "almond_extract 14\n",
      "almond_milk 1\n",
      "amaranth 13\n",
      "amaretti 11\n",
      "anchovy 22\n",
      "anchovy_essence 6\n",
      "angelica 3\n",
      "bitters 4\n",
      "anise 5\n",
      "apple 45\n",
      "apple_chutney 9\n",
      "apple_juice 28\n",
      "apple_sauce 10\n",
      "apricot 24\n",
      "apricot_jam 15\n",
      "arborio_rice 14\n",
      "arbroath_smokie 7\n",
      "argan_oil 1\n",
      "arrowroot 18\n",
      "artichoke 19\n",
      "asafoetida 11\n",
      "asparagus 24\n",
      "aubergine 23\n",
      "avocado 25\n",
      "bacon 32\n",
      "bagel 12\n",
      "baguette 22\n",
      "baked_beans 6\n",
      "cakes_and_baking 16\n",
      "baking_powder 31\n",
      "balsamic_vinegar 36\n",
      "bamboo_shoots 11\n",
      "banana 32\n",
      "banana_bread 7\n",
      "barbary_duck 3\n",
      "barbecue_sauce 11\n",
      "barley 9\n",
      "basil 37\n",
      "basmati_rice 24\n",
      "bay_boletes 0\n",
      "bay_leaf 36\n",
      "bean 16\n",
      "beansprouts 16\n",
      "bechamel_sauce 8\n",
      "beef 17\n",
      "beef_consomme 2\n",
      "beef_dripping 13\n",
      "beef_mince 13\n",
      "beef_ribs 7\n",
      "beef_rump 5\n",
      "beef_sausage 6\n",
      "beef_stock 20\n",
      "beef_tomato 15\n",
      "beer 20\n",
      "beetroot 36\n",
      "berry 20\n",
      "betel_leaves 0\n",
      "beurre_manie 1\n",
      "bicarbonate_of_soda 26\n",
      "bilberries 0\n",
      "birds-eye_chillies 12\n",
      "biscotti 10\n",
      "biscuit 21\n",
      "blachan 4\n",
      "black_beans 11\n",
      "black_bream 0\n",
      "black_eyed_bean 4\n",
      "black_pepper 44\n",
      "black_pudding 20\n",
      "black_sesame_seeds 13\n",
      "black_treacle 17\n",
      "blackbean_sauce 5\n",
      "blackberry 24\n",
      "blackcurrant 19\n",
      "blackcurrant_juice_drink 3\n",
      "blini 14\n",
      "blood_orange 11\n",
      "blueberry 26\n",
      "boar 8\n",
      "bok_choi 8\n",
      "bonito 8\n",
      "borage 7\n",
      "borlotti_bean 9\n",
      "bouquet_garni 11\n",
      "beef_braising_steak 9\n",
      "bramley_apple 26\n",
      "bran 10\n",
      "brandy 36\n",
      "brandy_butter 9\n",
      "brandy_snaps 9\n",
      "bratwurst 1\n",
      "brazil_nut 7\n",
      "bread 41\n",
      "bread_roll 15\n",
      "bread_sauce 7\n",
      "breadcrumbs 37\n",
      "breadfruit 1\n",
      "breadsticks 5\n",
      "bresaola 1\n",
      "brie_cheese 10\n",
      "brill 7\n",
      "brioche 35\n",
      "beef_brisket 7\n",
      "broad_beans 24\n",
      "broccoli 19\n",
      "broth 13\n",
      "brown_bread 10\n",
      "brown_lentil 1\n",
      "brown_rice 6\n",
      "brown_sauce 9\n",
      "shrimp 15\n",
      "brown_sugar 44\n",
      "brussels_sprouts 14\n",
      "buckwheat 6\n",
      "buckwheat_flour 16\n",
      "bulgur_wheat 12\n",
      "bun 13\n",
      "beef_burger 7\n",
      "butter 40\n",
      "butter_bean 15\n",
      "buttercream_icing 4\n",
      "butterhead_lettuce 6\n",
      "buttermilk 26\n",
      "butternut_squash 29\n",
      "cabbage 16\n",
      "caerphilly_cheese 4\n",
      "cake 18\n",
      "calasparra_rice 3\n",
      "calvados 17\n",
      "camembert_cheese 7\n",
      "campagne_loaf 0\n",
      "candied_peel 12\n",
      "cannellini_beans 14\n",
      "cape_gooseberries 6\n",
      "capers 28\n",
      "capsicum 2\n",
      "caramel 7\n",
      "caraway_seeds 19\n",
      "cardamom 40\n",
      "carob 1\n",
      "carrageen_moss 0\n",
      "best_end 7\n",
      "carrot 37\n",
      "carrot_cake 8\n",
      "cashew 27\n",
      "cassava 2\n",
      "caster_sugar 47\n",
      "catfish 0\n",
      "caul_fat 3\n",
      "cauliflower 26\n",
      "cava 2\n",
      "caviar 10\n",
      "cavolo_nero 9\n",
      "cayenne_pepper 34\n",
      "celeriac 26\n",
      "celery 30\n",
      "celery_seeds 2\n",
      "champ 4\n",
      "champagne 20\n",
      "chanterelle_mushrooms 13\n",
      "chantilly_cream 3\n",
      "chapati_flour 8\n",
      "chapatis 5\n",
      "charcuterie 1\n",
      "chard 11\n",
      "charlotte_potato 7\n",
      "chayote 0\n",
      "cheddar_cheese 32\n",
      "cheese 32\n",
      "cheese_sauce 7\n",
      "cherry 28\n",
      "cherry_brandy 14\n",
      "cherry_tomatoes 29\n",
      "chervil 20\n",
      "cheshire_cheese 4\n",
      "chestnut 33\n",
      "chestnut_mushroom 18\n",
      "chicken 20\n",
      "chicken_breast 18\n",
      "chicken_leg 13\n",
      "chicken_liver 18\n",
      "chicken_soup 10\n",
      "chicken_stock 30\n",
      "chicken_thigh 15\n",
      "chicken_wing 17\n",
      "chickpea 23\n",
      "chickpea_flour 14\n",
      "chicory 15\n",
      "chilli 41\n",
      "chilli_con_carne 8\n",
      "chilli_oil 16\n",
      "chilli_paste 11\n",
      "chilli_powder 35\n",
      "chilli_sauce 19\n",
      "chinese_cabbage 13\n",
      "chinese_mushrooms 8\n",
      "chinese_pancake 5\n",
      "chipotle 9\n",
      "chips 17\n",
      "chives 32\n",
      "chocolate 19\n",
      "chocolate_biscuit 10\n",
      "chocolate_brownies 7\n",
      "chocolate_cake 14\n",
      "chocolate_mousse 7\n",
      "chocolate_truffle 12\n",
      "chopped_tomatoes 22\n",
      "chorizo 26\n",
      "choux_pastry 9\n",
      "christmas_cake 8\n",
      "christmas_pudding 14\n",
      "beef_chuck_and_blade 5\n",
      "chump 7\n",
      "chutney 19\n",
      "ciabatta 21\n",
      "cider 25\n",
      "cinnamon 45\n",
      "citrus_fruit 3\n",
      "clams 13\n",
      "clarified_butter 26\n",
      "clementine 22\n",
      "clotted_cream 14\n",
      "cloves 41\n",
      "cobnut 11\n",
      "cockles 10\n",
      "cocktails 8\n",
      "cocoa_butter 1\n",
      "cocoa 19\n",
      "coconut 31\n",
      "coconut_cream 20\n",
      "coconut_flour 3\n",
      "coconut_milk 32\n",
      "coconut_oil 16\n",
      "cod 15\n",
      "cod_roe 0\n",
      "coffee 16\n",
      "coffee_beans 8\n",
      "coffee_essence 13\n",
      "coffee_granules 10\n",
      "coffee_liqueur 11\n",
      "cognac 16\n",
      "cola 11\n",
      "coleslaw 10\n",
      "coley 5\n",
      "collar 4\n",
      "compote 10\n",
      "comte_cheese 2\n",
      "condensed_milk 15\n",
      "coriander 31\n",
      "coriander_cress 19\n",
      "coriander_seeds 28\n",
      "corn_oil 11\n",
      "corn_syrup 0\n",
      "corned_beef 12\n",
      "cornflour 32\n",
      "cos_lettuce 12\n",
      "cottage_cheese 10\n",
      "coulis 2\n",
      "courgette 34\n",
      "court_bouillon 0\n",
      "couscous 15\n",
      "crab 17\n",
      "crab_apple 1\n",
      "crackers 13\n",
      "cranberry 38\n",
      "cranberry_juice 7\n",
      "cranberry_sauce 20\n",
      "crayfish 12\n",
      "cream 31\n",
      "cream_cheese 27\n",
      "cream_liqueur 6\n",
      "cream_of_tartar 15\n",
      "cream_soda 3\n",
      "creamed_coconut 11\n",
      "creme_fraiche 34\n",
      "crepe 10\n",
      "cress 19\n",
      "crispbread 3\n",
      "crisps 12\n",
      "croissant 5\n",
      "crostini 8\n",
      "croutons 6\n",
      "crudites 2\n",
      "crumble 9\n",
      "crystallised_ginger 10\n",
      "cucumber 32\n",
      "cumberland_sauce 4\n",
      "cumin 31\n",
      "curacao 2\n",
      "curd 7\n",
      "curd_cheese 12\n",
      "curly_kale 7\n",
      "currant_bread 0\n",
      "currant 19\n",
      "curry 11\n",
      "curry_leaves 18\n",
      "curry_paste 24\n",
      "curry_powder 22\n",
      "custard 17\n",
      "custard_powder 9\n",
      "cuttlefish 3\n",
      "dab 0\n",
      "daikon 11\n",
      "dal 12\n",
      "damsons 4\n",
      "dandelion 9\n",
      "danish_blue 0\n",
      "dark_chocolate 24\n",
      "date 25\n",
      "demerara_sugar 34\n",
      "demi-glace_sauce 0\n",
      "dessicated_coconut 19\n",
      "desiree_potato 7\n",
      "digestive_biscuit 10\n",
      "dijon_mustard 28\n",
      "dill 26\n",
      "dim_sum_wrappers 4\n",
      "dolcelatte_cheese 10\n",
      "double_cream 45\n",
      "double_gloucester 1\n",
      "dover_sole 7\n",
      "dragon_fruit 7\n",
      "dried_apricot 31\n",
      "dried_cherries 13\n",
      "dried_chilli 31\n",
      "dried_fruit 15\n",
      "dried_mixed_fruit 7\n",
      "dry_sherry 22\n",
      "duck 19\n",
      "duck_confit 9\n",
      "duck_fat 13\n",
      "dulce_de_leche 12\n",
      "dumplings 1\n",
      "duxelles 1\n",
      "edam 1\n",
      "eel 8\n",
      "egg 45\n",
      "egg_wash 28\n",
      "egg_white 33\n",
      "egg_yolk 40\n",
      "elderberries 2\n",
      "elderflower 20\n",
      "emmental_cheese 12\n",
      "english_muffin 7\n",
      "english_mustard 29\n",
      "escalope 7\n",
      "evaporated_milk 13\n",
      "exotic_fruit 4\n",
      "falafel 9\n",
      "farfalle 7\n",
      "fat 15\n",
      "fennel 25\n",
      "fennel_seeds 30\n",
      "fenugreek 14\n",
      "feta_cheese 30\n",
      "fettuccine 6\n",
      "field_mushroom 10\n",
      "fig 28\n",
      "beef_fillet 13\n",
      "filo_pastry 24\n",
      "fish 9\n",
      "fish_roe 3\n",
      "fish_sauce 20\n",
      "fish_soup 14\n",
      "five-spice_powder 15\n",
      "flageolet_bean 10\n",
      "flaked_almonds 35\n",
      "beef_flank 2\n",
      "flapjacks 8\n",
      "flatbread 29\n",
      "flatfish 3\n",
      "fleur_de_sel 5\n",
      "flour 38\n",
      "tortilla_flour 18\n",
      "floury_potato 24\n",
      "flying_fish 0\n",
      "focaccia 12\n",
      "foie_gras 0\n",
      "fondant_icing 8\n",
      "fondant_potatoes 3\n",
      "fontina_cheese 7\n",
      "food_colouring 13\n",
      "forced_rhubarb 6\n",
      "fortified_wine 0\n",
      "fragrant_rice 4\n",
      "frangipane 2\n",
      "frankfurter 0\n",
      "freekeh 4\n",
      "french_beans 15\n",
      "french_bread 12\n",
      "french_dressing 11\n",
      "coriander_fresh 31\n",
      "tuna_fresh 15\n",
      "fromage_frais 7\n",
      "fruit 8\n",
      "fruit_brandy 3\n",
      "fruit_cake 6\n",
      "fruit_juice 4\n",
      "fruit_salad 9\n",
      "fudge 14\n",
      "fusilli 7\n",
      "galangal 19\n",
      "game 10\n",
      "gammon 8\n",
      "garam_masala 23\n",
      "garlic 36\n",
      "garlic_and_herb_cream_cheese 10\n",
      "garlic_bread 6\n",
      "gelatine 27\n",
      "ghee 13\n",
      "gherkin 19\n",
      "giblets 4\n",
      "gin 14\n",
      "ginger 42\n",
      "ginger_ale 9\n",
      "ginger_beer 6\n",
      "ginger_biscuit 12\n",
      "gingerbread 10\n",
      "glace_cherries 10\n",
      "globe_artichoke 8\n",
      "glucose 16\n",
      "gnocchi 15\n",
      "goats_cheese 25\n",
      "goats_milk 2\n",
      "golden_syrup 19\n",
      "goose 9\n",
      "goose_fat 11\n",
      "gooseberry 15\n",
      "gorgonzola_cheese 16\n",
      "gouda_cheese 1\n",
      "grain 12\n",
      "gram_flour 17\n",
      "grape_juice 0\n",
      "grapefruit 20\n",
      "grapefruit_juice 11\n",
      "grapes 20\n",
      "grapeseed_oil 10\n",
      "gratin 14\n",
      "gravy 15\n",
      "gravy_browning 7\n",
      "green_banana 1\n",
      "green_bean 20\n",
      "green_cabbage 11\n",
      "green_lentil 7\n",
      "green_tea 5\n",
      "greengages 4\n",
      "grey_mullet 6\n",
      "ground_almonds 22\n",
      "ginger_ground 32\n",
      "grouse 6\n",
      "gruyere_cheese 23\n",
      "guacamole 5\n",
      "guava 3\n",
      "guinea_fowl 5\n",
      "gurnard 7\n",
      "habanero_chillies 0\n",
      "haddock 9\n",
      "haggis 7\n",
      "hake 6\n",
      "halibut 11\n",
      "halloumi_cheese 14\n",
      "ham 29\n",
      "hare 3\n",
      "haricot_bean 10\n",
      "harissa 8\n",
      "hazelnut 40\n",
      "hazelnut_oil 15\n",
      "heart 5\n",
      "herbal_liqueur 0\n",
      "herbal_tea 1\n",
      "herbes_de_provence 3\n",
      "herb 23\n",
      "herring 8\n",
      "hogget 5\n",
      "hoisin_sauce 8\n",
      "hoki 4\n",
      "hollandaise_sauce 8\n",
      "hominy 2\n",
      "honey 45\n",
      "honeycomb 8\n",
      "horseradish 19\n",
      "horseradish_sauce 15\n",
      "hot_cross_buns 6\n",
      "hummus 16\n",
      "hunza_apricots 1\n",
      "hyssop 0\n",
      "ice_cream 21\n",
      "iceberg_lettuce 16\n",
      "icing 14\n",
      "icing_sugar 29\n",
      "irish_stout 11\n",
      "jaggery 6\n",
      "jam 20\n",
      "january_king_cabbage 2\n",
      "japanese_pumpkin 0\n",
      "jelly 16\n",
      "jerk_seasoning 7\n",
      "jersey_royal_potatoes 14\n",
      "jerusalem_artichoke 16\n",
      "john_dory 5\n",
      "jujube 0\n",
      "juniper_berries 17\n",
      "jus 5\n",
      "kabana 0\n",
      "kale 19\n",
      "ketchup 20\n",
      "ketjap_manis 5\n",
      "kidney 13\n",
      "kidney_bean 17\n",
      "king_edward_potato 23\n",
      "kipper 7\n",
      "kirsch 15\n",
      "kiwi_fruit 9\n",
      "kohlrabi 9\n",
      "kumquat 5\n",
      "lager 9\n",
      "lamb 12\n",
      "lamb_breast 9\n",
      "lamb_chop 8\n",
      "lamb_fillet 9\n",
      "lamb_kidney 5\n",
      "lamb_loin 8\n",
      "lamb_mince 16\n",
      "lamb_neck 7\n",
      "lamb_rump 5\n",
      "lamb_shank 7\n",
      "lamb_shoulder 8\n",
      "lamb_stock 7\n",
      "lancashire_cheese 4\n",
      "langoustine 15\n",
      "lard 32\n",
      "lardons 17\n",
      "lasagne 11\n",
      "lasagne_sheets 7\n",
      "laverbread 3\n",
      "leek 29\n",
      "leftover_turkey 10\n",
      "lamb_leg 7\n",
      "lemon 47\n",
      "lemon_balm 9\n",
      "lemon_curd 13\n",
      "lemon_juice 45\n",
      "lemon_sole 10\n",
      "lemonade 8\n",
      "lemongrass 26\n",
      "lentils 16\n",
      "lettuce 18\n",
      "lime 45\n",
      "lime_cordial 3\n",
      "lime_juice 36\n",
      "lime_leaves 22\n",
      "lime_pickle 1\n",
      "ling 7\n",
      "lingonberry 4\n",
      "linguine 11\n",
      "liqueur 27\n",
      "liquorice 12\n",
      "little_gem_lettuce 17\n",
      "liver 12\n",
      "loaf_cake 6\n",
      "lobster 14\n",
      "loganberry 1\n",
      "long-grain_rice 13\n",
      "lovage 7\n",
      "low-calorie_sweeteners 0\n",
      "lychee 9\n",
      "macadamia_nuts 15\n",
      "macaroni 7\n",
      "macaroon 10\n",
      "mace 23\n",
      "mackerel 18\n",
      "madeira 18\n",
      "madeira_cake 12\n",
      "madeleines 7\n",
      "maize 15\n",
      "malted_grain_bread 0\n",
      "manchego_cheese 16\n",
      "mandarin 5\n",
      "mangetout 17\n",
      "mango 31\n",
      "mango_chutney 14\n",
      "mango_juice 2\n",
      "mango_pickle 1\n",
      "mangosteen 0\n",
      "maple_syrup 27\n",
      "margarine 20\n",
      "marjoram 15\n",
      "marmalade 22\n",
      "marrow 7\n",
      "marrowfat_peas 5\n",
      "marsala_wine 19\n",
      "marshmallow 17\n",
      "marzipan 12\n",
      "mascarpone_cheese 20\n",
      "mashed_potato 24\n",
      "matzo 2\n",
      "mayonnaise 26\n",
      "meat 3\n",
      "medlars 1\n",
      "megrim 2\n",
      "melon 16\n",
      "melon_seeds 0\n",
      "meringue 19\n",
      "mesclun 0\n",
      "milk 45\n",
      "milk_chocolate 12\n",
      "milkshake 2\n",
      "millet 1\n",
      "millet_flour 1\n",
      "mince 11\n",
      "mince_pies 8\n",
      "mincemeat 17\n",
      "mint 44\n",
      "mint_sauce 10\n",
      "mirepoix 1\n",
      "mirin 14\n",
      "miso 13\n",
      "mixed_berries 14\n",
      "mixed_dried_beans 0\n",
      "mixed_fish 0\n",
      "mixed_nuts 6\n",
      "mixed_spice 19\n",
      "mixed_spices 20\n",
      "molasses 10\n",
      "monks_beard 1\n",
      "monkfish 9\n",
      "morel 7\n",
      "mortadella 3\n",
      "mozzarella_cheese 22\n",
      "muesli 10\n",
      "muffins 11\n",
      "mulberries 1\n",
      "mulled_wine 6\n",
      "mung_bean 2\n",
      "mushroom 30\n",
      "mussel 17\n",
      "mustard 25\n",
      "mustard_cress 14\n",
      "mustard_leaves 2\n",
      "mustard_oil 0\n",
      "mustard_powder 22\n",
      "mustard_seeds 27\n",
      "mutton 8\n",
      "naan_bread 14\n",
      "nachos 4\n",
      "nashi 3\n",
      "nasturtium 10\n",
      "nectarine 8\n",
      "nettles 7\n",
      "new_potatoes 24\n",
      "nibbed_almonds 2\n",
      "noodle_soup 13\n",
      "noodle 13\n",
      "nori 7\n",
      "nougat 5\n",
      "nut 17\n",
      "nutmeg 44\n",
      "oatcake 11\n",
      "oatmeal 20\n",
      "oats 28\n",
      "octopus 7\n",
      "offal 3\n",
      "oil 40\n",
      "oily_fish 2\n",
      "okra 6\n",
      "olive 25\n",
      "olive_oil 40\n",
      "onion 35\n",
      "orange 47\n",
      "orange_juice 28\n",
      "orange_liqueur 17\n",
      "oregano 27\n",
      "ouzo 1\n",
      "beef_oxtail 8\n",
      "oyster 16\n",
      "oyster_mushroom 14\n",
      "oyster_sauce 14\n",
      "paella 12\n",
      "pak_choi 14\n",
      "palm_oil 1\n",
      "palm_sugar 17\n",
      "pancake 23\n",
      "pancetta 28\n",
      "pandan_leaves 2\n",
      "paneer 11\n",
      "panettone 11\n",
      "papaya 11\n",
      "pappardelle 9\n",
      "paprika 32\n",
      "parfait 11\n",
      "parmesan_cheese 37\n",
      "parsley 33\n",
      "parsnip 22\n",
      "partridge 8\n",
      "passata 21\n",
      "passion_fruit 16\n",
      "passion_fruit_juice 3\n",
      "pasta 23\n",
      "pastrami 2\n",
      "pastry 17\n",
      "pasty 23\n",
      "pate 10\n",
      "paw-paw 1\n",
      "pea_shoots 16\n",
      "peach 27\n",
      "peanut_butter 20\n",
      "peanut_oil 21\n",
      "peanut 28\n",
      "pear 35\n",
      "pearl_barley 6\n",
      "pea 24\n",
      "pecan_nut 28\n",
      "pecorino_cheese 16\n",
      "pectin 13\n",
      "peel 15\n",
      "penne 8\n",
      "pepper 41\n",
      "peppercorn 33\n",
      "pepperoni 3\n",
      "perch 1\n",
      "perry 3\n",
      "pesto 24\n",
      "pheasant 13\n",
      "piccalilli 9\n",
      "pickle 21\n",
      "pickled_onion 6\n",
      "pie 19\n",
      "pig_cheeks 2\n",
      "pigeon 12\n",
      "pigeon_peas 4\n",
      "pike 0\n",
      "pine_nut 30\n",
      "pineapple 31\n",
      "pineapple_juice 15\n",
      "pink_fir_apple 5\n",
      "pink_peppercorn 9\n",
      "pinto_bean 6\n",
      "piri-piri 7\n",
      "pistachio 35\n",
      "pitta_bread 20\n",
      "pizza 13\n",
      "plaice 9\n",
      "plain_flour 42\n",
      "plantain 7\n",
      "plum 30\n",
      "polenta 30\n",
      "pollack 7\n",
      "pollock 9\n",
      "pomegranate 27\n",
      "pomegranate_juice 6\n",
      "pomegranate_molasses 9\n",
      "pomelo 5\n",
      "popcorn 5\n",
      "poppy_seeds 21\n",
      "porcini 11\n",
      "pork 19\n",
      "pork_belly 17\n",
      "pork_chop 7\n",
      "pork_fillet 8\n",
      "pork_leg 2\n",
      "pork_loin 11\n",
      "pork_mince 14\n",
      "pork_sausages 16\n",
      "pork_shoulder 14\n",
      "pork_spare_rib 9\n",
      "port 24\n",
      "portobello_mushrooms 16\n",
      "potato 34\n",
      "potato_rosti 7\n",
      "potato_wedges 5\n",
      "poultry 1\n",
      "poussin 6\n",
      "praline 2\n",
      "prawn 18\n",
      "prawn_crackers 1\n",
      "preserved_lemons 12\n",
      "preserves 8\n",
      "prosciutto 24\n",
      "prune 22\n",
      "prune_juice 0\n",
      "pudding_rice 9\n",
      "puff_pastry 33\n",
      "pulled_pork 8\n",
      "pulse 1\n",
      "pumpernickel_bread 0\n",
      "pumpkin 33\n",
      "pumpkin_seed 30\n",
      "purple_sprouting_broccoli 13\n",
      "puy_lentils 14\n",
      "quail 15\n",
      "quails_egg 15\n",
      "quark 7\n",
      "quatre-epices 1\n",
      "quince 16\n",
      "quinoa 11\n",
      "rabbit 8\n",
      "lamb_rack 5\n",
      "radicchio 12\n",
      "radish 19\n",
      "rainbow_chard 4\n",
      "rainbow_trout 6\n",
      "raisins 41\n",
      "raita 5\n",
      "rapeseed_oil 27\n",
      "ras-el-hanout 6\n",
      "raspberry 23\n",
      "raspberry_jam 12\n",
      "ratafia_biscuits 3\n",
      "ratatouille 8\n",
      "red_cabbage 16\n",
      "red_leicester_cheese 2\n",
      "red_lentil 11\n",
      "red_mullet 10\n",
      "red_onion 35\n",
      "red_rice 2\n",
      "red_snapper 6\n",
      "red_wine 38\n",
      "red_wine_vinegar 34\n",
      "redcurrant 20\n",
      "redcurrant_jelly 18\n",
      "rennet 1\n",
      "rhubarb 26\n",
      "beef_rib 7\n",
      "rice 25\n",
      "rice_flour 21\n",
      "rice_noodle 15\n",
      "rice_pudding 7\n",
      "rice_vinegar 16\n",
      "rice_wine 18\n",
      "ricotta_cheese 28\n",
      "rigatoni 7\n",
      "risotto 11\n",
      "risotto_rice 9\n",
      "roast_beef 10\n",
      "roast_chicken 15\n",
      "roast_lamb 12\n",
      "roast_pork 8\n",
      "roast_potatoes 19\n",
      "roast_turkey 7\n",
      "roasted_vegetables 14\n",
      "rock_salmon 0\n",
      "rock_salt 19\n",
      "rocket 21\n",
      "root_beer 0\n",
      "root_vegetable 7\n",
      "roquefort_cheese 11\n",
      "rose_wine 0\n",
      "rosehip_syrup 2\n",
      "rosemary 36\n",
      "rosewater 15\n",
      "rouille 0\n",
      "royal_icing 8\n",
      "rum 26\n",
      "rump 8\n",
      "runner_bean 9\n",
      "rye_bread 16\n",
      "rye_flour 11\n",
      "safflower_oil 0\n",
      "saffron 33\n",
      "sage 32\n",
      "salad 39\n",
      "salad_cream 4\n",
      "salad_leaves 19\n",
      "salami 6\n",
      "salmon 18\n",
      "salsa 5\n",
      "salsify 7\n",
      "salt 44\n",
      "salted_beef 4\n",
      "salt_cod 13\n",
      "sambuca 0\n",
      "samphire 13\n",
      "sardine 11\n",
      "sashimi 1\n",
      "satsuma 12\n",
      "sauce 16\n",
      "saucisson 1\n",
      "sausage 36\n",
      "savory 1\n",
      "savoy_cabbage 15\n",
      "scallop 18\n",
      "scotch_bonnet_chillies 9\n",
      "scrag 5\n",
      "sea_bass 15\n",
      "sea_bream 10\n",
      "sea_salt 41\n",
      "sea_trout 7\n",
      "seafood 21\n",
      "seasoning 10\n",
      "seaweed 16\n",
      "seed 30\n",
      "self-raising_flour 30\n",
      "semolina 26\n",
      "serrano_ham 16\n",
      "sesame_oil 26\n",
      "sesame_seeds 33\n",
      "seville_orange 12\n",
      "shallot 32\n",
      "sharon_fruit 2\n",
      "shellfish 8\n",
      "sherry 23\n",
      "sherry_vinegar 23\n",
      "shiitake_mushroom 17\n",
      "beef_shin 7\n",
      "shortbread 19\n",
      "shortcrust_pastry 24\n",
      "sichuan_pepper 12\n",
      "beef_silverside 2\n",
      "single_cream 33\n",
      "beef_sirloin 13\n",
      "skate 5\n",
      "sloe 2\n",
      "sloe_gin 7\n",
      "smoked_cheese 7\n",
      "smoked_fish 0\n",
      "smoked_haddock 22\n",
      "smoked_mackerel 17\n",
      "smoked_salmon 23\n",
      "smoked_trout 11\n",
      "snapper 1\n",
      "soba_noodles 3\n",
      "soda 16\n",
      "soda_bread 11\n",
      "sole 8\n",
      "sorbet 10\n",
      "sorrel 14\n",
      "soup 17\n",
      "sourdough_bread 27\n",
      "soured_cream 32\n",
      "soy_sauce 23\n",
      "soya_bean 9\n",
      "soya_flour 0\n",
      "soya_milk 9\n",
      "soya_oil 0\n",
      "spaghetti 10\n",
      "spaghetti_squash 0\n",
      "sparkling_wine 7\n",
      "spelt 3\n",
      "spelt_flour 12\n",
      "spice 9\n",
      "spinach 26\n",
      "split_peas 7\n",
      "sponge_cake 11\n",
      "spring_greens 11\n",
      "spring_onion 30\n",
      "spring_roll_wrappers 10\n",
      "squash 9\n",
      "squid 17\n",
      "star_anise 37\n",
      "starfruit 0\n",
      "steak 11\n",
      "stem_ginger 20\n",
      "stew 8\n",
      "stewing_lamb 4\n",
      "stilton_cheese 28\n",
      "stock 28\n",
      "straw_mushroom 0\n",
      "strawberry 24\n",
      "strawberry_jam 15\n",
      "strega_liqueur 0\n",
      "strong_white_flour 31\n",
      "stuffing 20\n",
      "sucralose 1\n",
      "suet 19\n",
      "sugar 45\n",
      "sugar-snap_peas 7\n",
      "sultanas 32\n",
      "sumac 12\n",
      "summer_cabbage 0\n",
      "summer_fruit 5\n",
      "sunflower_oil 40\n",
      "sunflower_seed 25\n",
      "sushi_rice 11\n",
      "swede 15\n",
      "sweet_potato 23\n",
      "sweet_sherry 10\n",
      "sweetbread 4\n",
      "sweetcorn 28\n",
      "confectionery 16\n",
      "swiss_chard 10\n",
      "swiss_roll 16\n",
      "swordfish 4\n",
      "syrup 18\n",
      "t-bone_steak 7\n",
      "tabasco 20\n",
      "taco 10\n",
      "tagliatelle 9\n",
      "tahini 21\n",
      "taleggio_cheese 12\n",
      "tamari 4\n",
      "tamarillo 0\n",
      "tamarind 16\n",
      "tangerine 5\n",
      "tapenade 5\n",
      "tapioca 13\n",
      "taro 0\n",
      "tarragon 27\n",
      "tartare_sauce 4\n",
      "tayberry 4\n",
      "tea 16\n",
      "tempura 13\n",
      "tequila 12\n",
      "teriyaki 6\n",
      "teriyaki_sauce 9\n",
      "terrine 11\n",
      "thai_basil 12\n",
      "thyme 40\n",
      "tilapia 3\n",
      "tuna_tinned 14\n",
      "toffee 9\n",
      "tofu 16\n",
      "tomatillo 1\n",
      "tomato 38\n",
      "tomato_chutney 7\n",
      "tomato_juice 14\n",
      "tomato_puree 28\n",
      "tongue 7\n",
      "tonic 6\n",
      "beef_topside 7\n",
      "tortellini 8\n",
      "tripe 2\n",
      "trout 14\n",
      "truffle 20\n",
      "truffle_oil 19\n",
      "turbot 8\n",
      "turkey 9\n",
      "turkey_breast 8\n",
      "turkey_mince 8\n",
      "turkish_delight 1\n",
      "turmeric 30\n",
      "turnip 14\n",
      "unleavened_bread 0\n",
      "vacherin_cheese 1\n",
      "vanilla_essence 12\n",
      "vanilla_extract 25\n",
      "vanilla_pod 36\n",
      "veal 7\n",
      "vegetable_oil 40\n",
      "vegetable_shortening 10\n",
      "vegetable_stock 25\n",
      "vegetable 19\n",
      "vegetarian_sausage 6\n",
      "venison 16\n",
      "verjus 3\n",
      "vermicelli 8\n",
      "vermouth 21\n",
      "vine_leaves 6\n",
      "vinegar 37\n",
      "vodka 21\n",
      "vodka_cocktail 7\n",
      "waffles 11\n",
      "walnut 34\n",
      "walnut_oil 21\n",
      "wasabi 12\n",
      "water_chestnut 9\n",
      "watercress 23\n",
      "watermelon 17\n",
      "waxy_potato 14\n",
      "webbs_lettuce 1\n",
      "wensleydale_cheese 9\n",
      "wheatgerm 0\n",
      "whelk 2\n",
      "whipping_cream 26\n",
      "whisky 26\n",
      "whisky_cocktail 6\n",
      "whisky_liqueur 3\n",
      "white_bread 41\n",
      "white_cabbage 20\n",
      "white_chocolate 11\n",
      "white_fish 14\n",
      "white_pepper 30\n",
      "white_wine 34\n",
      "white_wine_vinegar 40\n",
      "whitebait 1\n",
      "whitecurrant 2\n",
      "whiting 6\n",
      "whole_wheat_pasta 13\n",
      "wholegrain_mustard 21\n",
      "wholemeal_bread 11\n",
      "wholemeal_flour 25\n",
      "wild_duck 14\n",
      "wild_garlic 10\n",
      "wild_mushroom 21\n",
      "wild_rice 9\n",
      "wine 16\n",
      "winkles 3\n",
      "wood_pigeon 6\n",
      "worcestershire_sauce 25\n",
      "wraps 19\n",
      "yam 6\n",
      "yeast 31\n",
      "yellow_lentil 7\n",
      "yoghurt 45\n",
      "yuzu 1\n",
      "zander 0\n",
      "zest 30\n"
     ]
    }
   ],
   "source": [
    "indexIngredients = {}\n",
    "indexRecipes = {}\n",
    "\n",
    "recipes = []\n",
    "for item in ingredients:\n",
    "    repeat = True\n",
    "    while (repeat):\n",
    "        try:\n",
    "            url = 'http://www.bbc.co.uk/food/' + item\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, \"lxml\")\n",
    "            thislist = extractRecipes(soup)\n",
    "            \n",
    "        except:\n",
    "            print(\"Error encountered while collecting\", item)\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            repeat = False\n",
    "                        \n",
    "    # produce short debug to keep track of progress\n",
    "    print(item, len(thislist))\n",
    "\n",
    "    recipes += thislist\n",
    "\n",
    "    # Update Ingredients index\n",
    "    indexIngredients[item] = thislist\n",
    "\n",
    "    # update Recipes index    \n",
    "    for recipe in thislist:\n",
    "        recipeIngredients = indexRecipes.get(recipe, [])        \n",
    "        recipeIngredients.append(item)\n",
    "        indexRecipes[recipe] = recipeIngredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barbecue_baby_back_ribs_42228',\n",
       " 'derry_duck_and_64105',\n",
       " 'roasted_salt_marsh_lamb_13899',\n",
       " 'roman-style_saltimbocca_44940',\n",
       " 'honeyandzaatarglazed_91314']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexIngredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barbecue_baby_back_ribs_42228',\n",
       " 'derry_duck_and_64105',\n",
       " 'roasted_salt_marsh_lamb_13899',\n",
       " 'roman-style_saltimbocca_44940',\n",
       " 'honeyandzaatarglazed_91314',\n",
       " 'terrineofcapricorngo_81701']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexIngredients['acidulated_water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexRecipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acidulated_water',\n",
       " 'anchovy',\n",
       " 'broad_beans',\n",
       " 'caster_sugar',\n",
       " 'escalope',\n",
       " 'globe_artichoke',\n",
       " 'lettuce',\n",
       " 'mint',\n",
       " 'pancetta',\n",
       " 'pear',\n",
       " 'pea',\n",
       " 'pecorino_cheese',\n",
       " 'plain_flour',\n",
       " 'prosciutto',\n",
       " 'sage',\n",
       " 'spring_onion',\n",
       " 'vegetable_stock',\n",
       " 'white_wine']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexRecipes['roman-style_saltimbocca_44940']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Recipes\n",
    "\n",
    "Now we are ready to go into each recipe and extract the information that we look for. Again, we use our browser to examine the HTML code:\n",
    "* The name of the recipe can be extracted from the title of the page\n",
    "* It seems that Preparation Time, Cooking Time and Number of Serving are all [HTML paragraph tags](https://www.w3schools.com/tags/tag_p.asp) that have assigned a custom attribute *itemprop*. \n",
    " * For Preparation Time the attribute is set to \"prepTime\"\n",
    " * For Cooking Time the attribute is set to \"cookTime\" \n",
    " * For Number of Services the attribute is set to \"recipeYield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.bbc.co.uk/food/recipes/roman-style_saltimbocca_44940'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the title is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BBC Food - Recipes - Roman-style saltimbocca with caramelised pear, fried sage and vignarola'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = soup.title.contents[0][21:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the other fields will be done using the *find_all* command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 mins to 1 hour\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(itemprop='prepTime'):\n",
    "    print(tag.contents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we are ready to build our final function that extracts the contents of each recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractRecipe(soup):\n",
    "    recipe = {'title': soup.title.contents[0][21:]}       \n",
    "    \n",
    "    for tag in soup.find_all(itemprop='prepTime'):\n",
    "        recipe['preptime'] = tag.contents[0]\n",
    "\n",
    "    for tag in soup.find_all(itemprop='cookTime'):\n",
    "        recipe['cookTime'] = tag.contents[0]\n",
    "        \n",
    "    for tag in soup.find_all(itemprop='recipeYield'):\n",
    "        recipe['recipeYield'] = tag.contents[0]  \n",
    "        \n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can do the final step, go through all the recipes and scrap the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataRecipes = {}\n",
    "for recipe in recipes:\n",
    "    url = 'https://www.bbc.co.uk/food/recipes/' + recipe\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    dataRecipes[recipe] = extractRecipe(soup)\n",
    "    dataRecipes[recipe]['url'] = url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "* Implement a simple error handling code for the above iteration to make sure that scraping continues even in the case of connectivity errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cookTime': '30 mins to 1 hour',\n",
       " 'preptime': '30 mins to 1 hour',\n",
       " 'recipeYield': 'Serves 4',\n",
       " 'title': 'Roman-style saltimbocca with caramelised pear, fried sage and vignarola',\n",
       " 'url': 'https://www.bbc.co.uk/food/recipes/roman-style_saltimbocca_44940'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRecipes['roman-style_saltimbocca_44940']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store scraped data on a Document Store\n",
    "\n",
    "We now wish to store the contents of the dataset into a document database where each row becomes a separate document. We will use the [MongoDB](https://www.mongodb.com/what-is-mongodb) and the Database-as-a-service provider [mLab](https://mlab.com/).\n",
    "\n",
    "Step-by-step introductory for the Data API can be found under the [Data Manipulation using Lazio Bar/Restaurant Dataset](lab-restaurants/ADM%20Lab%20-%20Restaurants.ipynb) laboratory page.\n",
    "\n",
    "**Make sure you replace your API key in the code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'apiKey': '<Paste your api key HERE>'}\n",
    "url = 'https://api.mlab.com/api/1/databases'\n",
    "response = requests.get(url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ \"adm\" , \"adm2017\" , \"ds\" , \"seed\" ]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dbname = 'adm2017'\n",
    "collection = 'recipes'\n",
    "url = 'https://api.mlab.com/api/1/databases/' + dbname + '/collections/' + collection\n",
    "headers = {'content-type': 'application/json'}\n",
    "data = json.dumps(dataRecipes['roman-style_saltimbocca_44940'])\n",
    "response = requests.post(url, data=data, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this simple test to make sure that everything works as it should, let's now upload all the information extracted along with the indexes to our document store. Here we can use the batch upload documents as discussed in the [Data Manipulation using Lazio Bar/Restaurant Dataset](lab-restaurants/ADM%20Lab%20-%20Restaurants.ipynb) laboratory.\n",
    "\n",
    "We need to convert the dictionary into a list of documents. In the process we can also include in each recipe the list of ingredients used by using the reverse index that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipesList = []\n",
    "for key,item in dataRecipes.items():\n",
    "    item['ingredients'] = indexRecipes[key]\n",
    "    recipesList.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look how this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cookTime': '10 to 30 mins',\n",
       " 'ingredients': ['almond',\n",
       "  'chicken_breast',\n",
       "  'cucumber',\n",
       "  'olive_oil',\n",
       "  'paprika',\n",
       "  'parsley',\n",
       "  'salt',\n",
       "  'sunflower_oil',\n",
       "  'whipping_cream'],\n",
       " 'preptime': 'less than 30 mins',\n",
       " 'recipeYield': 'Serves 4',\n",
       " 'title': 'Chicken and cucumber en papillote with toasted almonds',\n",
       " 'url': 'https://www.bbc.co.uk/food/recipes/chicken_and_cucumber_en_93986'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipesList[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to batch upload all the recipes to mLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.dumps(recipesList)\n",
    "response = requests.post(url, data=data, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "* Upload all the ingredients along with the index of recipes.\n",
    "* Extend the recipes scraping by including:\n",
    " * Name of the chef\n",
    " * Name of show where the recipe was presented\n",
    " * Link to the image\n",
    "* Extend the recipes scraping by also extrecting the preparation instructions.\n",
    "* Update recipe documents in mLab with the additional information retrieved.\n",
    "* Create a new index for recipes related to:\n",
    " * Cuisines based on *http://www.bbc.co.uk/food/cuisines*\n",
    " * Seasons based on *http://www.bbc.co.uk/food/seasons*\n",
    " * Occasions based on *http://www.bbc.co.uk/food/occasions*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
